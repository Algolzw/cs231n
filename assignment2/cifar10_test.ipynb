{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# best acc: (resnet-56: val-92.15%， test-90.11%)\n",
    "# best acc: (resnet-110: val-95.00%， test-(93.91%))\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device('cuda')\n",
    "torch.cuda.set_device(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAIN = 48000\n",
    "print_every = 370\n",
    "\n",
    "transform_train = T.Compose([\n",
    "        T.RandomCrop(32, padding=4),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "transform = T.Compose([\n",
    "                T.ToTensor(),\n",
    "                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "            ])\n",
    "\n",
    "cifar10_train = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "                             transform=transform_train)\n",
    "loader_train = DataLoader(cifar10_train, batch_size=128,\n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "cifar10_val = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "                           transform=transform)\n",
    "loader_val = DataLoader(cifar10_val, batch_size=100, \n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
    "\n",
    "cifar10_test = dset.CIFAR10('./cs231n/datasets', train=False, download=True, \n",
    "                            transform=transform)\n",
    "loader_test = DataLoader(cifar10_test, batch_size=64)\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0], -1)\n",
    "    \n",
    "def check_accuracy_part34(loader, model, device=device):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=torch.float32)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f%%)' % (num_correct, num_samples, 100 * acc))\n",
    "    return acc\n",
    "\n",
    "def train_part34(model, optimizer, epochs=1):\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=torch.float32)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print('Epoch:(%d) Iteration %d, loss = %.4f' % (e, t, loss.item()))\n",
    "                check_accuracy_part34(loader_val, model)\n",
    "                print()\n",
    "\n",
    "def train(model, optimizer, epochs=1, scheduler=None, device=device):\n",
    "    model = model.to(device)  # move the model parameters to CPU/GPU\n",
    "#     summary(model, (3, 32, 32))\n",
    "    best_acc = 0\n",
    "    best_ep = 0\n",
    "    loss_his = []\n",
    "    acc_his = []\n",
    "    for e in range(epochs):\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=torch.float32)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if t>0 and t % print_every == 0:\n",
    "                loss_his.append(loss)\n",
    "                model.eval()\n",
    "                print('Epoch:(%d/%d) Iteration %d, loss = %.4f' % (e, epochs, t, loss.item()))\n",
    "                acc = check_accuracy_part34(loader_val, model, device=device)\n",
    "                acc_his.append(acc)\n",
    "                if acc > best_acc:\n",
    "                    best_acc = acc\n",
    "                    best_ep = e\n",
    "                print()\n",
    "                model.train()\n",
    "    return best_acc, best_ep, loss_his, acc_his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:(0/200) Iteration 370, loss = 1.3242\n",
      "Checking accuracy on validation set\n",
      "Got 872 / 2000 correct (43.60%)\n",
      "\n",
      "Epoch:(1/200) Iteration 370, loss = 0.9786\n",
      "Checking accuracy on validation set\n",
      "Got 1238 / 2000 correct (61.90%)\n",
      "\n",
      "Epoch:(2/200) Iteration 370, loss = 0.7570\n",
      "Checking accuracy on validation set\n",
      "Got 1297 / 2000 correct (64.85%)\n",
      "\n",
      "Epoch:(3/200) Iteration 370, loss = 0.7228\n",
      "Checking accuracy on validation set\n",
      "Got 1528 / 2000 correct (76.40%)\n",
      "\n",
      "Epoch:(4/200) Iteration 370, loss = 0.6292\n",
      "Checking accuracy on validation set\n",
      "Got 1389 / 2000 correct (69.45%)\n",
      "\n",
      "Epoch:(5/200) Iteration 370, loss = 0.6438\n",
      "Checking accuracy on validation set\n",
      "Got 1426 / 2000 correct (71.30%)\n",
      "\n",
      "Epoch:(6/200) Iteration 370, loss = 0.5342\n",
      "Checking accuracy on validation set\n",
      "Got 1487 / 2000 correct (74.35%)\n",
      "\n",
      "Epoch:(7/200) Iteration 370, loss = 0.6282\n",
      "Checking accuracy on validation set\n",
      "Got 1607 / 2000 correct (80.35%)\n",
      "\n",
      "Epoch:(8/200) Iteration 370, loss = 0.5194\n",
      "Checking accuracy on validation set\n",
      "Got 1542 / 2000 correct (77.10%)\n",
      "\n",
      "Epoch:(9/200) Iteration 370, loss = 0.6627\n",
      "Checking accuracy on validation set\n",
      "Got 1559 / 2000 correct (77.95%)\n",
      "\n",
      "Epoch:(10/200) Iteration 370, loss = 0.5871\n",
      "Checking accuracy on validation set\n",
      "Got 1514 / 2000 correct (75.70%)\n",
      "\n",
      "Epoch:(11/200) Iteration 370, loss = 0.4777\n",
      "Checking accuracy on validation set\n",
      "Got 1533 / 2000 correct (76.65%)\n",
      "\n",
      "Epoch:(12/200) Iteration 370, loss = 0.5083\n",
      "Checking accuracy on validation set\n",
      "Got 1535 / 2000 correct (76.75%)\n",
      "\n",
      "Epoch:(13/200) Iteration 370, loss = 0.3135\n",
      "Checking accuracy on validation set\n",
      "Got 1437 / 2000 correct (71.85%)\n",
      "\n",
      "Epoch:(14/200) Iteration 370, loss = 0.4764\n",
      "Checking accuracy on validation set\n",
      "Got 1442 / 2000 correct (72.10%)\n",
      "\n",
      "Epoch:(15/200) Iteration 370, loss = 0.4519\n",
      "Checking accuracy on validation set\n",
      "Got 1590 / 2000 correct (79.50%)\n",
      "\n",
      "Epoch:(16/200) Iteration 370, loss = 0.3629\n",
      "Checking accuracy on validation set\n",
      "Got 1555 / 2000 correct (77.75%)\n",
      "\n",
      "Epoch:(17/200) Iteration 370, loss = 0.4522\n",
      "Checking accuracy on validation set\n",
      "Got 1442 / 2000 correct (72.10%)\n",
      "\n",
      "Epoch:(18/200) Iteration 370, loss = 0.3759\n",
      "Checking accuracy on validation set\n",
      "Got 1451 / 2000 correct (72.55%)\n",
      "\n",
      "Epoch:(19/200) Iteration 370, loss = 0.6083\n",
      "Checking accuracy on validation set\n",
      "Got 1621 / 2000 correct (81.05%)\n",
      "\n",
      "Epoch:(20/200) Iteration 370, loss = 0.4028\n",
      "Checking accuracy on validation set\n",
      "Got 1673 / 2000 correct (83.65%)\n",
      "\n",
      "Epoch:(21/200) Iteration 370, loss = 0.2962\n",
      "Checking accuracy on validation set\n",
      "Got 1626 / 2000 correct (81.30%)\n",
      "\n",
      "Epoch:(22/200) Iteration 370, loss = 0.4982\n",
      "Checking accuracy on validation set\n",
      "Got 1469 / 2000 correct (73.45%)\n",
      "\n",
      "Epoch:(23/200) Iteration 370, loss = 0.4435\n",
      "Checking accuracy on validation set\n",
      "Got 1551 / 2000 correct (77.55%)\n",
      "\n",
      "Epoch:(24/200) Iteration 370, loss = 0.4612\n",
      "Checking accuracy on validation set\n",
      "Got 1635 / 2000 correct (81.75%)\n",
      "\n",
      "Epoch:(25/200) Iteration 370, loss = 0.4384\n",
      "Checking accuracy on validation set\n",
      "Got 1622 / 2000 correct (81.10%)\n",
      "\n",
      "Epoch:(26/200) Iteration 370, loss = 0.4065\n",
      "Checking accuracy on validation set\n",
      "Got 1646 / 2000 correct (82.30%)\n",
      "\n",
      "Epoch:(27/200) Iteration 370, loss = 0.4916\n",
      "Checking accuracy on validation set\n",
      "Got 1612 / 2000 correct (80.60%)\n",
      "\n",
      "Epoch:(28/200) Iteration 370, loss = 0.5205\n",
      "Checking accuracy on validation set\n",
      "Got 1579 / 2000 correct (78.95%)\n",
      "\n",
      "Epoch:(29/200) Iteration 370, loss = 0.5275\n",
      "Checking accuracy on validation set\n",
      "Got 1627 / 2000 correct (81.35%)\n",
      "\n",
      "Epoch:(30/200) Iteration 370, loss = 0.5641\n",
      "Checking accuracy on validation set\n",
      "Got 1659 / 2000 correct (82.95%)\n",
      "\n",
      "Epoch:(31/200) Iteration 370, loss = 0.4746\n",
      "Checking accuracy on validation set\n",
      "Got 1685 / 2000 correct (84.25%)\n",
      "\n",
      "Epoch:(32/200) Iteration 370, loss = 0.4849\n",
      "Checking accuracy on validation set\n",
      "Got 1608 / 2000 correct (80.40%)\n",
      "\n",
      "Epoch:(33/200) Iteration 370, loss = 0.5182\n",
      "Checking accuracy on validation set\n",
      "Got 1515 / 2000 correct (75.75%)\n",
      "\n",
      "Epoch:(34/200) Iteration 370, loss = 0.3966\n",
      "Checking accuracy on validation set\n",
      "Got 1595 / 2000 correct (79.75%)\n",
      "\n",
      "Epoch:(35/200) Iteration 370, loss = 0.5711\n",
      "Checking accuracy on validation set\n",
      "Got 1664 / 2000 correct (83.20%)\n",
      "\n",
      "Epoch:(36/200) Iteration 370, loss = 0.3853\n",
      "Checking accuracy on validation set\n",
      "Got 1650 / 2000 correct (82.50%)\n",
      "\n",
      "Epoch:(37/200) Iteration 370, loss = 0.3687\n",
      "Checking accuracy on validation set\n",
      "Got 1685 / 2000 correct (84.25%)\n",
      "\n",
      "Epoch:(38/200) Iteration 370, loss = 0.4582\n",
      "Checking accuracy on validation set\n",
      "Got 1635 / 2000 correct (81.75%)\n",
      "\n",
      "Epoch:(39/200) Iteration 370, loss = 0.3358\n",
      "Checking accuracy on validation set\n",
      "Got 1550 / 2000 correct (77.50%)\n",
      "\n",
      "Epoch:(40/200) Iteration 370, loss = 0.5891\n",
      "Checking accuracy on validation set\n",
      "Got 1655 / 2000 correct (82.75%)\n",
      "\n",
      "Epoch:(41/200) Iteration 370, loss = 0.4705\n",
      "Checking accuracy on validation set\n",
      "Got 1659 / 2000 correct (82.95%)\n",
      "\n",
      "Epoch:(42/200) Iteration 370, loss = 0.5318\n",
      "Checking accuracy on validation set\n",
      "Got 1666 / 2000 correct (83.30%)\n",
      "\n",
      "Epoch:(43/200) Iteration 370, loss = 0.3726\n",
      "Checking accuracy on validation set\n",
      "Got 1429 / 2000 correct (71.45%)\n",
      "\n",
      "Epoch:(44/200) Iteration 370, loss = 0.3737\n",
      "Checking accuracy on validation set\n",
      "Got 1618 / 2000 correct (80.90%)\n",
      "\n",
      "Epoch:(45/200) Iteration 370, loss = 0.3547\n",
      "Checking accuracy on validation set\n",
      "Got 1687 / 2000 correct (84.35%)\n",
      "\n",
      "Epoch:(46/200) Iteration 370, loss = 0.4715\n",
      "Checking accuracy on validation set\n",
      "Got 1695 / 2000 correct (84.75%)\n",
      "\n",
      "Epoch:(47/200) Iteration 370, loss = 0.2963\n",
      "Checking accuracy on validation set\n",
      "Got 1687 / 2000 correct (84.35%)\n",
      "\n",
      "Epoch:(48/200) Iteration 370, loss = 0.4419\n",
      "Checking accuracy on validation set\n",
      "Got 1654 / 2000 correct (82.70%)\n",
      "\n",
      "Epoch:(49/200) Iteration 370, loss = 0.3826\n",
      "Checking accuracy on validation set\n",
      "Got 1576 / 2000 correct (78.80%)\n",
      "\n",
      "Epoch:(50/200) Iteration 370, loss = 0.4622\n",
      "Checking accuracy on validation set\n",
      "Got 1711 / 2000 correct (85.55%)\n",
      "\n",
      "Epoch:(51/200) Iteration 370, loss = 0.3733\n",
      "Checking accuracy on validation set\n",
      "Got 1701 / 2000 correct (85.05%)\n",
      "\n",
      "Epoch:(52/200) Iteration 370, loss = 0.3341\n",
      "Checking accuracy on validation set\n",
      "Got 1577 / 2000 correct (78.85%)\n",
      "\n",
      "Epoch:(53/200) Iteration 370, loss = 0.4961\n",
      "Checking accuracy on validation set\n",
      "Got 1589 / 2000 correct (79.45%)\n",
      "\n",
      "Epoch:(54/200) Iteration 370, loss = 0.3729\n",
      "Checking accuracy on validation set\n",
      "Got 1615 / 2000 correct (80.75%)\n",
      "\n",
      "Epoch:(55/200) Iteration 370, loss = 0.4568\n",
      "Checking accuracy on validation set\n",
      "Got 1625 / 2000 correct (81.25%)\n",
      "\n",
      "Epoch:(56/200) Iteration 370, loss = 0.3037\n",
      "Checking accuracy on validation set\n",
      "Got 1629 / 2000 correct (81.45%)\n",
      "\n",
      "Epoch:(57/200) Iteration 370, loss = 0.5645\n",
      "Checking accuracy on validation set\n",
      "Got 1574 / 2000 correct (78.70%)\n",
      "\n",
      "Epoch:(58/200) Iteration 370, loss = 0.2231\n",
      "Checking accuracy on validation set\n",
      "Got 1668 / 2000 correct (83.40%)\n",
      "\n",
      "Epoch:(59/200) Iteration 370, loss = 0.4159\n",
      "Checking accuracy on validation set\n",
      "Got 1585 / 2000 correct (79.25%)\n",
      "\n",
      "Epoch:(60/200) Iteration 370, loss = 0.3950\n",
      "Checking accuracy on validation set\n",
      "Got 1725 / 2000 correct (86.25%)\n",
      "\n",
      "Epoch:(61/200) Iteration 370, loss = 0.3684\n",
      "Checking accuracy on validation set\n",
      "Got 1618 / 2000 correct (80.90%)\n",
      "\n",
      "Epoch:(62/200) Iteration 370, loss = 0.1959\n",
      "Checking accuracy on validation set\n",
      "Got 1573 / 2000 correct (78.65%)\n",
      "\n",
      "Epoch:(63/200) Iteration 370, loss = 0.4011\n",
      "Checking accuracy on validation set\n",
      "Got 1718 / 2000 correct (85.90%)\n",
      "\n",
      "Epoch:(64/200) Iteration 370, loss = 0.2762\n",
      "Checking accuracy on validation set\n",
      "Got 1691 / 2000 correct (84.55%)\n",
      "\n",
      "Epoch:(65/200) Iteration 370, loss = 0.3234\n",
      "Checking accuracy on validation set\n",
      "Got 1615 / 2000 correct (80.75%)\n",
      "\n",
      "Epoch:(66/200) Iteration 370, loss = 0.4087\n",
      "Checking accuracy on validation set\n",
      "Got 1657 / 2000 correct (82.85%)\n",
      "\n",
      "Epoch:(67/200) Iteration 370, loss = 0.5017\n",
      "Checking accuracy on validation set\n",
      "Got 1563 / 2000 correct (78.15%)\n",
      "\n",
      "Epoch:(68/200) Iteration 370, loss = 0.3180\n",
      "Checking accuracy on validation set\n",
      "Got 1470 / 2000 correct (73.50%)\n",
      "\n",
      "Epoch:(69/200) Iteration 370, loss = 0.4023\n",
      "Checking accuracy on validation set\n",
      "Got 1578 / 2000 correct (78.90%)\n",
      "\n",
      "Epoch:(70/200) Iteration 370, loss = 0.3604\n",
      "Checking accuracy on validation set\n",
      "Got 1634 / 2000 correct (81.70%)\n",
      "\n",
      "Epoch:(71/200) Iteration 370, loss = 0.2683\n",
      "Checking accuracy on validation set\n",
      "Got 1698 / 2000 correct (84.90%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:(72/200) Iteration 370, loss = 0.3276\n",
      "Checking accuracy on validation set\n",
      "Got 1690 / 2000 correct (84.50%)\n",
      "\n",
      "Epoch:(73/200) Iteration 370, loss = 0.4277\n",
      "Checking accuracy on validation set\n",
      "Got 1739 / 2000 correct (86.95%)\n",
      "\n",
      "Epoch:(74/200) Iteration 370, loss = 0.4177\n",
      "Checking accuracy on validation set\n",
      "Got 1699 / 2000 correct (84.95%)\n",
      "\n",
      "Epoch:(75/200) Iteration 370, loss = 0.3284\n",
      "Checking accuracy on validation set\n",
      "Got 1687 / 2000 correct (84.35%)\n",
      "\n",
      "Epoch:(76/200) Iteration 370, loss = 0.3119\n",
      "Checking accuracy on validation set\n",
      "Got 1679 / 2000 correct (83.95%)\n",
      "\n",
      "Epoch:(77/200) Iteration 370, loss = 0.3246\n",
      "Checking accuracy on validation set\n",
      "Got 1615 / 2000 correct (80.75%)\n",
      "\n",
      "Epoch:(78/200) Iteration 370, loss = 0.4139\n",
      "Checking accuracy on validation set\n",
      "Got 1430 / 2000 correct (71.50%)\n",
      "\n",
      "Epoch:(79/200) Iteration 370, loss = 0.2704\n",
      "Checking accuracy on validation set\n",
      "Got 1627 / 2000 correct (81.35%)\n",
      "\n",
      "Epoch:(80/200) Iteration 370, loss = 0.4407\n",
      "Checking accuracy on validation set\n",
      "Got 1624 / 2000 correct (81.20%)\n",
      "\n",
      "Epoch:(81/200) Iteration 370, loss = 0.4068\n",
      "Checking accuracy on validation set\n",
      "Got 1551 / 2000 correct (77.55%)\n",
      "\n",
      "Epoch:(82/200) Iteration 370, loss = 0.3688\n",
      "Checking accuracy on validation set\n",
      "Got 1705 / 2000 correct (85.25%)\n",
      "\n",
      "Epoch:(83/200) Iteration 370, loss = 0.4357\n",
      "Checking accuracy on validation set\n",
      "Got 1638 / 2000 correct (81.90%)\n",
      "\n",
      "Epoch:(84/200) Iteration 370, loss = 0.3299\n",
      "Checking accuracy on validation set\n",
      "Got 1634 / 2000 correct (81.70%)\n",
      "\n",
      "Epoch:(85/200) Iteration 370, loss = 0.3899\n",
      "Checking accuracy on validation set\n",
      "Got 1682 / 2000 correct (84.10%)\n",
      "\n",
      "Epoch:(86/200) Iteration 370, loss = 0.3155\n",
      "Checking accuracy on validation set\n",
      "Got 1617 / 2000 correct (80.85%)\n",
      "\n",
      "Epoch:(87/200) Iteration 370, loss = 0.3825\n",
      "Checking accuracy on validation set\n",
      "Got 1653 / 2000 correct (82.65%)\n",
      "\n",
      "Epoch:(88/200) Iteration 370, loss = 0.3672\n",
      "Checking accuracy on validation set\n",
      "Got 1677 / 2000 correct (83.85%)\n",
      "\n",
      "Epoch:(89/200) Iteration 370, loss = 0.3296\n",
      "Checking accuracy on validation set\n",
      "Got 1685 / 2000 correct (84.25%)\n",
      "\n",
      "Epoch:(90/200) Iteration 370, loss = 0.2608\n",
      "Checking accuracy on validation set\n",
      "Got 1656 / 2000 correct (82.80%)\n",
      "\n",
      "Epoch:(91/200) Iteration 370, loss = 0.3933\n",
      "Checking accuracy on validation set\n",
      "Got 1658 / 2000 correct (82.90%)\n",
      "\n",
      "Epoch:(92/200) Iteration 370, loss = 0.3696\n",
      "Checking accuracy on validation set\n",
      "Got 1711 / 2000 correct (85.55%)\n",
      "\n",
      "Epoch:(93/200) Iteration 370, loss = 0.3704\n",
      "Checking accuracy on validation set\n",
      "Got 1687 / 2000 correct (84.35%)\n",
      "\n",
      "Epoch:(94/200) Iteration 370, loss = 0.4187\n",
      "Checking accuracy on validation set\n",
      "Got 1685 / 2000 correct (84.25%)\n",
      "\n",
      "Epoch:(95/200) Iteration 370, loss = 0.3121\n",
      "Checking accuracy on validation set\n",
      "Got 1670 / 2000 correct (83.50%)\n",
      "\n",
      "Epoch:(96/200) Iteration 370, loss = 0.3398\n",
      "Checking accuracy on validation set\n",
      "Got 1683 / 2000 correct (84.15%)\n",
      "\n",
      "Epoch:(97/200) Iteration 370, loss = 0.2950\n",
      "Checking accuracy on validation set\n",
      "Got 1622 / 2000 correct (81.10%)\n",
      "\n",
      "Epoch:(98/200) Iteration 370, loss = 0.3608\n",
      "Checking accuracy on validation set\n",
      "Got 1675 / 2000 correct (83.75%)\n",
      "\n",
      "Epoch:(99/200) Iteration 370, loss = 0.2384\n",
      "Checking accuracy on validation set\n",
      "Got 1686 / 2000 correct (84.30%)\n",
      "\n",
      "Epoch:(100/200) Iteration 370, loss = 0.2368\n",
      "Checking accuracy on validation set\n",
      "Got 1855 / 2000 correct (92.75%)\n",
      "\n",
      "Epoch:(101/200) Iteration 370, loss = 0.2161\n",
      "Checking accuracy on validation set\n",
      "Got 1861 / 2000 correct (93.05%)\n",
      "\n",
      "Epoch:(102/200) Iteration 370, loss = 0.1346\n",
      "Checking accuracy on validation set\n",
      "Got 1868 / 2000 correct (93.40%)\n",
      "\n",
      "Epoch:(103/200) Iteration 370, loss = 0.2171\n",
      "Checking accuracy on validation set\n",
      "Got 1872 / 2000 correct (93.60%)\n",
      "\n",
      "Epoch:(104/200) Iteration 370, loss = 0.1874\n",
      "Checking accuracy on validation set\n",
      "Got 1871 / 2000 correct (93.55%)\n",
      "\n",
      "Epoch:(105/200) Iteration 370, loss = 0.1187\n",
      "Checking accuracy on validation set\n",
      "Got 1869 / 2000 correct (93.45%)\n",
      "\n",
      "Epoch:(106/200) Iteration 370, loss = 0.1432\n",
      "Checking accuracy on validation set\n",
      "Got 1879 / 2000 correct (93.95%)\n",
      "\n",
      "Epoch:(107/200) Iteration 370, loss = 0.0703\n",
      "Checking accuracy on validation set\n",
      "Got 1873 / 2000 correct (93.65%)\n",
      "\n",
      "Epoch:(108/200) Iteration 370, loss = 0.1031\n",
      "Checking accuracy on validation set\n",
      "Got 1864 / 2000 correct (93.20%)\n",
      "\n",
      "Epoch:(109/200) Iteration 370, loss = 0.0605\n",
      "Checking accuracy on validation set\n",
      "Got 1863 / 2000 correct (93.15%)\n",
      "\n",
      "Epoch:(110/200) Iteration 370, loss = 0.1020\n",
      "Checking accuracy on validation set\n",
      "Got 1867 / 2000 correct (93.35%)\n",
      "\n",
      "Epoch:(111/200) Iteration 370, loss = 0.0999\n",
      "Checking accuracy on validation set\n",
      "Got 1866 / 2000 correct (93.30%)\n",
      "\n",
      "Epoch:(112/200) Iteration 370, loss = 0.0846\n",
      "Checking accuracy on validation set\n",
      "Got 1873 / 2000 correct (93.65%)\n",
      "\n",
      "Epoch:(113/200) Iteration 370, loss = 0.1333\n",
      "Checking accuracy on validation set\n",
      "Got 1870 / 2000 correct (93.50%)\n",
      "\n",
      "Epoch:(114/200) Iteration 370, loss = 0.0992\n",
      "Checking accuracy on validation set\n",
      "Got 1860 / 2000 correct (93.00%)\n",
      "\n",
      "Epoch:(115/200) Iteration 370, loss = 0.0396\n",
      "Checking accuracy on validation set\n",
      "Got 1870 / 2000 correct (93.50%)\n",
      "\n",
      "Epoch:(116/200) Iteration 370, loss = 0.0575\n",
      "Checking accuracy on validation set\n",
      "Got 1856 / 2000 correct (92.80%)\n",
      "\n",
      "Epoch:(117/200) Iteration 370, loss = 0.1245\n",
      "Checking accuracy on validation set\n",
      "Got 1862 / 2000 correct (93.10%)\n",
      "\n",
      "Epoch:(118/200) Iteration 370, loss = 0.0323\n",
      "Checking accuracy on validation set\n",
      "Got 1856 / 2000 correct (92.80%)\n",
      "\n",
      "Epoch:(119/200) Iteration 370, loss = 0.0323\n",
      "Checking accuracy on validation set\n",
      "Got 1861 / 2000 correct (93.05%)\n",
      "\n",
      "Epoch:(120/200) Iteration 370, loss = 0.0414\n",
      "Checking accuracy on validation set\n",
      "Got 1860 / 2000 correct (93.00%)\n",
      "\n",
      "Epoch:(121/200) Iteration 370, loss = 0.1379\n",
      "Checking accuracy on validation set\n",
      "Got 1851 / 2000 correct (92.55%)\n",
      "\n",
      "Epoch:(122/200) Iteration 370, loss = 0.0740\n",
      "Checking accuracy on validation set\n",
      "Got 1841 / 2000 correct (92.05%)\n",
      "\n",
      "Epoch:(123/200) Iteration 370, loss = 0.0686\n",
      "Checking accuracy on validation set\n",
      "Got 1858 / 2000 correct (92.90%)\n",
      "\n",
      "Epoch:(124/200) Iteration 370, loss = 0.1325\n",
      "Checking accuracy on validation set\n",
      "Got 1851 / 2000 correct (92.55%)\n",
      "\n",
      "Epoch:(125/200) Iteration 370, loss = 0.0898\n",
      "Checking accuracy on validation set\n",
      "Got 1854 / 2000 correct (92.70%)\n",
      "\n",
      "Epoch:(126/200) Iteration 370, loss = 0.1026\n",
      "Checking accuracy on validation set\n",
      "Got 1851 / 2000 correct (92.55%)\n",
      "\n",
      "Epoch:(127/200) Iteration 370, loss = 0.0462\n",
      "Checking accuracy on validation set\n",
      "Got 1843 / 2000 correct (92.15%)\n",
      "\n",
      "Epoch:(128/200) Iteration 370, loss = 0.0832\n",
      "Checking accuracy on validation set\n",
      "Got 1845 / 2000 correct (92.25%)\n",
      "\n",
      "Epoch:(129/200) Iteration 370, loss = 0.1261\n",
      "Checking accuracy on validation set\n",
      "Got 1827 / 2000 correct (91.35%)\n",
      "\n",
      "Epoch:(130/200) Iteration 370, loss = 0.1192\n",
      "Checking accuracy on validation set\n",
      "Got 1837 / 2000 correct (91.85%)\n",
      "\n",
      "Epoch:(131/200) Iteration 370, loss = 0.1869\n",
      "Checking accuracy on validation set\n",
      "Got 1834 / 2000 correct (91.70%)\n",
      "\n",
      "Epoch:(132/200) Iteration 370, loss = 0.1581\n",
      "Checking accuracy on validation set\n",
      "Got 1820 / 2000 correct (91.00%)\n",
      "\n",
      "Epoch:(133/200) Iteration 370, loss = 0.0833\n",
      "Checking accuracy on validation set\n",
      "Got 1837 / 2000 correct (91.85%)\n",
      "\n",
      "Epoch:(134/200) Iteration 370, loss = 0.0660\n",
      "Checking accuracy on validation set\n",
      "Got 1841 / 2000 correct (92.05%)\n",
      "\n",
      "Epoch:(135/200) Iteration 370, loss = 0.0961\n",
      "Checking accuracy on validation set\n",
      "Got 1847 / 2000 correct (92.35%)\n",
      "\n",
      "Epoch:(136/200) Iteration 370, loss = 0.1241\n",
      "Checking accuracy on validation set\n",
      "Got 1827 / 2000 correct (91.35%)\n",
      "\n",
      "Epoch:(137/200) Iteration 370, loss = 0.0854\n",
      "Checking accuracy on validation set\n",
      "Got 1856 / 2000 correct (92.80%)\n",
      "\n",
      "Epoch:(138/200) Iteration 370, loss = 0.1203\n",
      "Checking accuracy on validation set\n",
      "Got 1841 / 2000 correct (92.05%)\n",
      "\n",
      "Epoch:(139/200) Iteration 370, loss = 0.1048\n",
      "Checking accuracy on validation set\n",
      "Got 1833 / 2000 correct (91.65%)\n",
      "\n",
      "Epoch:(140/200) Iteration 370, loss = 0.0647\n",
      "Checking accuracy on validation set\n",
      "Got 1855 / 2000 correct (92.75%)\n",
      "\n",
      "Epoch:(141/200) Iteration 370, loss = 0.0457\n",
      "Checking accuracy on validation set\n",
      "Got 1834 / 2000 correct (91.70%)\n",
      "\n",
      "Epoch:(142/200) Iteration 370, loss = 0.0291\n",
      "Checking accuracy on validation set\n",
      "Got 1848 / 2000 correct (92.40%)\n",
      "\n",
      "Epoch:(143/200) Iteration 370, loss = 0.0846\n",
      "Checking accuracy on validation set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1830 / 2000 correct (91.50%)\n",
      "\n",
      "Epoch:(144/200) Iteration 370, loss = 0.0387\n",
      "Checking accuracy on validation set\n",
      "Got 1826 / 2000 correct (91.30%)\n",
      "\n",
      "Epoch:(145/200) Iteration 370, loss = 0.0374\n",
      "Checking accuracy on validation set\n",
      "Got 1836 / 2000 correct (91.80%)\n",
      "\n",
      "Epoch:(146/200) Iteration 370, loss = 0.0982\n",
      "Checking accuracy on validation set\n",
      "Got 1782 / 2000 correct (89.10%)\n",
      "\n",
      "Epoch:(147/200) Iteration 370, loss = 0.0859\n",
      "Checking accuracy on validation set\n",
      "Got 1848 / 2000 correct (92.40%)\n",
      "\n",
      "Epoch:(148/200) Iteration 370, loss = 0.0947\n",
      "Checking accuracy on validation set\n",
      "Got 1856 / 2000 correct (92.80%)\n",
      "\n",
      "Epoch:(149/200) Iteration 370, loss = 0.0743\n",
      "Checking accuracy on validation set\n",
      "Got 1842 / 2000 correct (92.10%)\n",
      "\n",
      "Epoch:(150/200) Iteration 370, loss = 0.0236\n",
      "Checking accuracy on validation set\n",
      "Got 1876 / 2000 correct (93.80%)\n",
      "\n",
      "Epoch:(151/200) Iteration 370, loss = 0.0338\n",
      "Checking accuracy on validation set\n",
      "Got 1888 / 2000 correct (94.40%)\n",
      "\n",
      "Epoch:(152/200) Iteration 370, loss = 0.0106\n",
      "Checking accuracy on validation set\n",
      "Got 1891 / 2000 correct (94.55%)\n",
      "\n",
      "Epoch:(153/200) Iteration 370, loss = 0.0242\n",
      "Checking accuracy on validation set\n",
      "Got 1892 / 2000 correct (94.60%)\n",
      "\n",
      "Epoch:(154/200) Iteration 370, loss = 0.0183\n",
      "Checking accuracy on validation set\n",
      "Got 1896 / 2000 correct (94.80%)\n",
      "\n",
      "Epoch:(155/200) Iteration 370, loss = 0.0137\n",
      "Checking accuracy on validation set\n",
      "Got 1892 / 2000 correct (94.60%)\n",
      "\n",
      "Epoch:(156/200) Iteration 370, loss = 0.0027\n",
      "Checking accuracy on validation set\n",
      "Got 1893 / 2000 correct (94.65%)\n",
      "\n",
      "Epoch:(157/200) Iteration 370, loss = 0.0159\n",
      "Checking accuracy on validation set\n",
      "Got 1892 / 2000 correct (94.60%)\n",
      "\n",
      "Epoch:(158/200) Iteration 370, loss = 0.0154\n",
      "Checking accuracy on validation set\n",
      "Got 1891 / 2000 correct (94.55%)\n",
      "\n",
      "Epoch:(159/200) Iteration 370, loss = 0.0087\n",
      "Checking accuracy on validation set\n",
      "Got 1896 / 2000 correct (94.80%)\n",
      "\n",
      "Epoch:(160/200) Iteration 370, loss = 0.0082\n",
      "Checking accuracy on validation set\n",
      "Got 1893 / 2000 correct (94.65%)\n",
      "\n",
      "Epoch:(161/200) Iteration 370, loss = 0.0062\n",
      "Checking accuracy on validation set\n",
      "Got 1892 / 2000 correct (94.60%)\n",
      "\n",
      "Epoch:(162/200) Iteration 370, loss = 0.0135\n",
      "Checking accuracy on validation set\n",
      "Got 1890 / 2000 correct (94.50%)\n",
      "\n",
      "Epoch:(163/200) Iteration 370, loss = 0.0085\n",
      "Checking accuracy on validation set\n",
      "Got 1899 / 2000 correct (94.95%)\n",
      "\n",
      "Epoch:(164/200) Iteration 370, loss = 0.0056\n",
      "Checking accuracy on validation set\n",
      "Got 1900 / 2000 correct (95.00%)\n",
      "\n",
      "Epoch:(165/200) Iteration 370, loss = 0.0042\n",
      "Checking accuracy on validation set\n",
      "Got 1896 / 2000 correct (94.80%)\n",
      "\n",
      "Epoch:(166/200) Iteration 370, loss = 0.0246\n",
      "Checking accuracy on validation set\n",
      "Got 1889 / 2000 correct (94.45%)\n",
      "\n",
      "Epoch:(167/200) Iteration 370, loss = 0.0099\n",
      "Checking accuracy on validation set\n",
      "Got 1887 / 2000 correct (94.35%)\n",
      "\n",
      "Epoch:(168/200) Iteration 370, loss = 0.0043\n",
      "Checking accuracy on validation set\n",
      "Got 1894 / 2000 correct (94.70%)\n",
      "\n",
      "Epoch:(169/200) Iteration 370, loss = 0.0122\n",
      "Checking accuracy on validation set\n",
      "Got 1895 / 2000 correct (94.75%)\n",
      "\n",
      "Epoch:(170/200) Iteration 370, loss = 0.0093\n",
      "Checking accuracy on validation set\n",
      "Got 1890 / 2000 correct (94.50%)\n",
      "\n",
      "Epoch:(171/200) Iteration 370, loss = 0.0124\n",
      "Checking accuracy on validation set\n",
      "Got 1892 / 2000 correct (94.60%)\n",
      "\n",
      "Epoch:(172/200) Iteration 370, loss = 0.0182\n",
      "Checking accuracy on validation set\n",
      "Got 1888 / 2000 correct (94.40%)\n",
      "\n",
      "Epoch:(173/200) Iteration 370, loss = 0.0032\n",
      "Checking accuracy on validation set\n",
      "Got 1889 / 2000 correct (94.45%)\n",
      "\n",
      "Epoch:(174/200) Iteration 370, loss = 0.0112\n",
      "Checking accuracy on validation set\n",
      "Got 1885 / 2000 correct (94.25%)\n",
      "\n",
      "Epoch:(175/200) Iteration 370, loss = 0.0205\n",
      "Checking accuracy on validation set\n",
      "Got 1890 / 2000 correct (94.50%)\n",
      "\n",
      "Epoch:(176/200) Iteration 370, loss = 0.0071\n",
      "Checking accuracy on validation set\n",
      "Got 1891 / 2000 correct (94.55%)\n",
      "\n",
      "Epoch:(177/200) Iteration 370, loss = 0.0049\n",
      "Checking accuracy on validation set\n",
      "Got 1886 / 2000 correct (94.30%)\n",
      "\n",
      "Epoch:(178/200) Iteration 370, loss = 0.0064\n",
      "Checking accuracy on validation set\n",
      "Got 1895 / 2000 correct (94.75%)\n",
      "\n",
      "Epoch:(179/200) Iteration 370, loss = 0.0040\n",
      "Checking accuracy on validation set\n",
      "Got 1893 / 2000 correct (94.65%)\n",
      "\n",
      "Epoch:(180/200) Iteration 370, loss = 0.0321\n",
      "Checking accuracy on validation set\n",
      "Got 1887 / 2000 correct (94.35%)\n",
      "\n",
      "Epoch:(181/200) Iteration 370, loss = 0.0085\n",
      "Checking accuracy on validation set\n",
      "Got 1887 / 2000 correct (94.35%)\n",
      "\n",
      "Epoch:(182/200) Iteration 370, loss = 0.0025\n",
      "Checking accuracy on validation set\n",
      "Got 1890 / 2000 correct (94.50%)\n",
      "\n",
      "Epoch:(183/200) Iteration 370, loss = 0.0031\n",
      "Checking accuracy on validation set\n",
      "Got 1896 / 2000 correct (94.80%)\n",
      "\n",
      "Epoch:(184/200) Iteration 370, loss = 0.0031\n",
      "Checking accuracy on validation set\n",
      "Got 1884 / 2000 correct (94.20%)\n",
      "\n",
      "Epoch:(185/200) Iteration 370, loss = 0.0036\n",
      "Checking accuracy on validation set\n",
      "Got 1896 / 2000 correct (94.80%)\n",
      "\n",
      "Epoch:(186/200) Iteration 370, loss = 0.0022\n",
      "Checking accuracy on validation set\n",
      "Got 1891 / 2000 correct (94.55%)\n",
      "\n",
      "Epoch:(187/200) Iteration 370, loss = 0.0023\n",
      "Checking accuracy on validation set\n",
      "Got 1887 / 2000 correct (94.35%)\n",
      "\n",
      "Epoch:(188/200) Iteration 370, loss = 0.0053\n",
      "Checking accuracy on validation set\n",
      "Got 1893 / 2000 correct (94.65%)\n",
      "\n",
      "Epoch:(189/200) Iteration 370, loss = 0.0036\n",
      "Checking accuracy on validation set\n",
      "Got 1888 / 2000 correct (94.40%)\n",
      "\n",
      "Epoch:(190/200) Iteration 370, loss = 0.0191\n",
      "Checking accuracy on validation set\n",
      "Got 1897 / 2000 correct (94.85%)\n",
      "\n",
      "Epoch:(191/200) Iteration 370, loss = 0.0384\n",
      "Checking accuracy on validation set\n",
      "Got 1894 / 2000 correct (94.70%)\n",
      "\n",
      "Epoch:(192/200) Iteration 370, loss = 0.0113\n",
      "Checking accuracy on validation set\n",
      "Got 1889 / 2000 correct (94.45%)\n",
      "\n",
      "Epoch:(193/200) Iteration 370, loss = 0.0061\n",
      "Checking accuracy on validation set\n",
      "Got 1893 / 2000 correct (94.65%)\n",
      "\n",
      "Epoch:(194/200) Iteration 370, loss = 0.0050\n",
      "Checking accuracy on validation set\n",
      "Got 1888 / 2000 correct (94.40%)\n",
      "\n",
      "Epoch:(195/200) Iteration 370, loss = 0.0028\n",
      "Checking accuracy on validation set\n",
      "Got 1890 / 2000 correct (94.50%)\n",
      "\n",
      "Epoch:(196/200) Iteration 370, loss = 0.0042\n",
      "Checking accuracy on validation set\n",
      "Got 1890 / 2000 correct (94.50%)\n",
      "\n",
      "Epoch:(197/200) Iteration 370, loss = 0.0015\n",
      "Checking accuracy on validation set\n",
      "Got 1888 / 2000 correct (94.40%)\n",
      "\n",
      "Epoch:(198/200) Iteration 370, loss = 0.0025\n",
      "Checking accuracy on validation set\n",
      "Got 1890 / 2000 correct (94.50%)\n",
      "\n",
      "Epoch:(199/200) Iteration 370, loss = 0.0030\n",
      "Checking accuracy on validation set\n",
      "Got 1893 / 2000 correct (94.65%)\n",
      "\n",
      "finish2\n",
      "epoch:164, best accuracy:95.00%\n"
     ]
    }
   ],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super().__init__()\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        self.flag = in_channels != out_channels\n",
    "        if self.flag:\n",
    "            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride=2, padding=padding, bias=False)\n",
    "            self.short_cut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 1, stride=2, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding, bias=False)\n",
    "            self.short_cut = nn.Sequential()\n",
    "            \n",
    "        nn.init.kaiming_normal_(self.conv1.weight)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, padding=padding, bias=False)\n",
    "        nn.init.kaiming_normal_(self.conv2.weight)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        layer1 = self.conv1(F.relu(self.bn1(x)))\n",
    "        layer2 = self.conv2(F.relu(self.bn2(layer1)))\n",
    "        \n",
    "        if self.flag:\n",
    "            out = layer2 + self.short_cut(x)\n",
    "        else:\n",
    "            out = layer2 + x\n",
    "        return out\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size):\n",
    "        super().__init__()\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        middle_channel = out_channel // 4\n",
    "        self.flag = in_channel != out_channel\n",
    "        self.conv1 = nn.Conv2d(in_channel, middle_channel, 1, stride=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(middle_channel)\n",
    "        \n",
    "        if self.flag:\n",
    "            self.conv2 = nn.Conv2d(middle_channel, middle_channel, kernel_size, stride=2, padding=padding, bias=False)\n",
    "            self.short_cut = nn.Sequential(\n",
    "                nn.Conv2d(in_channel, out_channel, 1, stride=2, bias=False),\n",
    "                nn.BatchNorm2d(out_channel)\n",
    "            )\n",
    "        else:\n",
    "            self.conv2 = nn.Conv2d(middle_channel, middle_channel, kernel_size, padding=padding, bias=False)\n",
    "            self.short_cut = nn.Sequential()\n",
    "\n",
    "        self.bn2 = nn.BatchNorm2d(middle_channel)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(middle_channel, out_channel, kernel_size, padding=padding, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channel)\n",
    "        nn.init.kaiming_normal_(self.conv1.weight)\n",
    "        nn.init.kaiming_normal_(self.conv2.weight)\n",
    "        nn.init.kaiming_normal_(self.conv3.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        layer1 = F.relu(self.bn1(self.conv1(x)))\n",
    "        layer2 = F.relu(self.bn2(self.conv2(layer1)))\n",
    "        layer3 = self.bn3(self.conv3(layer2))\n",
    "        \n",
    "        if self.flag:\n",
    "            out = F.relu(layer3 + self.short_cut(residual))\n",
    "        else:\n",
    "            out = F.relu(layer3 + x)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_layer = nn.Sequential(\n",
    "#             nn.BatchNorm2d(3),\n",
    "            nn.Conv2d(3, 16, 3, padding=1, bias=False)\n",
    "#             nn.BatchNorm2d(16),\n",
    "#             nn.ReLU(True)\n",
    "#             nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.layer1 = self.build_layer(16, 16, 18, BasicBlock)          # 32\n",
    "        self.layer2 = self.build_layer(16, 32, 18, BasicBlock)         # 16\n",
    "        self.layer3 = self.build_layer(32, 64, 18, BasicBlock)        # 8\n",
    "#         self.layer4 = self.build_layer(256, 512, 3, BasicBlock)        # 4\n",
    "        self.bn = nn.BatchNorm2d(64)\n",
    "        self.avgpool = nn.AvgPool2d(8)\n",
    "        self.classifier = nn.Linear(64, 10)\n",
    "        \n",
    "    def build_layer(self, in_channels, out_channels, num_blocks, block=BasicBlock):\n",
    "        layers = []\n",
    "        first_block = block(in_channels, out_channels, 3)\n",
    "        layers.append(first_block)\n",
    "        for i in range(num_blocks - 1):\n",
    "            layers.append(block(out_channels, out_channels, 3))\n",
    "\n",
    "#         layers.append(nn.Dropout2d(0.1))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        head = self.input_layer(x)\n",
    "        layer_1 = self.layer1(head)\n",
    "        layer_2 = self.layer2(layer_1)\n",
    "        layer_3 = F.relu(self.bn(self.layer3(layer_2)))\n",
    "#         layer_4 = self.layer4(layer_3)\n",
    "        out = self.avgpool(layer_3).view(x.shape[0], -1)\n",
    "\n",
    "        return self.classifier(out)\n",
    "\n",
    "model = ResNet()\n",
    "# model = nn.DataParallel(model, device_ids=[7,0,1,2,3,4,5,6])\n",
    "\n",
    "learning_rate = 1e-1\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=5e-4)\n",
    "scheduler = MultiStepLR(optimizer, milestones=[100, 150], gamma=0.1)\n",
    "best_acc, ep, loss_his, acc_his = train(model, optimizer, epochs=200, scheduler=scheduler, device=device)\n",
    "print('finish2\\nepoch:%d, best accuracy:%.2f%%' % (ep, best_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbe8015ca90>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_his)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "class PretrainedModel(nn.Module):\n",
    "    def __init__(self, state_dict=None):\n",
    "        super().__init__()\n",
    "        self.resnet = models.resnet101()\n",
    "        self.resnet.load_state_dict(state_dict)\n",
    "        num_ftrs = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(num_ftrs, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "model_url = 'https://www.flyai.com/m/resnet101-5d3b4d8f.pth'\n",
    "state_dict = torch.utils.model_zoo.load_url(model_url)\n",
    "\n",
    "model = PretrainedModel(state_dict)\n",
    "\n",
    "learning_rate = 1e-3\n",
    "# optimizer = optim.SGD(model2.parameters(), lr=learning_rate, momentum=0.9, weight_decay=1e-4)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = MultiStepLR(optimizer, milestones=[30, 50], gamma=0.1)\n",
    "best_acc, ep = train(model, optimizer, epochs=30, scheduler=scheduler, device=device)\n",
    "print('finish2\\nepoch:%d, best accuracy:%.2f%%' % (ep, best_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 47991 / 48000 correct (99.98%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9998125"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_accuracy_part34(loader_train, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on test set\n",
      "Got 9391 / 10000 correct (93.91%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9391"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_accuracy_part34(loader_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
